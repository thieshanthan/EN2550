{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Assignment a02\n",
    "### A. Thieshanthan, 180641N"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import string\n",
    "from os import path\n",
    "\n",
    "def plot_square(P, ax, color = '#6699cc'):\n",
    "    P=P/P[-1, :]\n",
    "    P=np.insert(P, 4, P[:,0], axis=1)\n",
    "    x=P[0, :]\n",
    "    y=P[1, :]\n",
    "    ax.plot(x, y, color = color, alpha=0.7, linewidth=3, solid_capstyle='round', zorder=2)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "def save_img(img, name):\n",
    "    dir = 'outputs/' + name + '.jpg'\n",
    "    cv.imwrite(dir, img)"
   ]
  },
  {
   "source": [
    "## 1. Using the code given to experimenting various types of 2D transformations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'outputs/2dtransforms.png'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e73452150008>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mplot_square\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPt2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m#cyan - scaled up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'outputs/2dtransforms'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda_new\\envs\\TensorFlow-GPU\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda_new\\envs\\TensorFlow-GPU\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   2309\u001b[0m                 \u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_edgecolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2311\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2313\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransparent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda_new\\envs\\TensorFlow-GPU\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2209\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2210\u001b[1;33m                 result = print_method(\n\u001b[0m\u001b[0;32m   2211\u001b[0m                     \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2212\u001b[0m                     \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda_new\\envs\\TensorFlow-GPU\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1637\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1639\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda_new\\envs\\TensorFlow-GPU\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[0;32m    508\u001b[0m         \"\"\"\n\u001b[0;32m    509\u001b[0m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m         mpl.image.imsave(\n\u001b[0m\u001b[0;32m    511\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"upper\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m             dpi=self.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n",
      "\u001b[1;32mD:\\Anaconda_new\\envs\\TensorFlow-GPU\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"format\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1610\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dpi\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1611\u001b[1;33m         \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpil_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda_new\\envs\\TensorFlow-GPU\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2159\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r+b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2160\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2161\u001b[1;33m                 \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w+b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2163\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'outputs/2dtransforms.png'"
     ]
    }
   ],
   "source": [
    "# points\n",
    "a, b, c, d = (0,0,1), (0,1,1), (1.5,.5,1), (1,0,1)\n",
    "P = np.array([a,b,c,d]).T\n",
    "\n",
    "\n",
    "t = np.pi/3\n",
    "H = [[np.cos(t), np.sin(t),0.],\n",
    "    [-np.sin(t), np.cos(t),0.], \n",
    "    [0.,0.,1.]]\n",
    "\n",
    "Pt = np.matmul(H,P)\n",
    "\n",
    "t = 0\n",
    "H1 = [[np.cos(t), np.sin(t),1.],\n",
    "    [-np.sin(t), np.cos(t),1.], \n",
    "    [0.,0.,1]]\n",
    "Pt1 = np.matmul(H1, P)\n",
    "\n",
    "t = 0\n",
    "H2 = [[np.cos(t), np.sin(t),0.],\n",
    "    [-np.sin(t), np.cos(t),0.], \n",
    "    [0.,0.,0.4]]\n",
    "Pt2 = np.matmul(H2, P)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, sharex=True, sharey=True)\n",
    "plot_square(P, ax, 'b')         #original square - blue\n",
    "plot_square(Pt, ax, 'y')        #Yellow - rotated 60 degrees\n",
    "plot_square(Pt1, ax, 'r')       #Red - tranlated\n",
    "plot_square(Pt2, ax, 'c')       #cyan - scaled up\n",
    "\n",
    "plt.savefig('outputs/2dtransforms')"
   ]
  },
  {
   "source": [
    "## 2. Transforming graffiti images using provided code"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6510e48cc11f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mim1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'images/img1.ppm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_ANYCOLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mim5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'images/img5.ppm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_ANYCOLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msave_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'im1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msave_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'im5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "im1 = cv.imread('images/img1.ppm', cv.IMREAD_ANYCOLOR)\n",
    "im5 = cv.imread('images/img5.ppm', cv.IMREAD_ANYCOLOR)\n",
    "\n",
    "save_img(im1, 'im1')\n",
    "save_img(im5, 'im5')\n",
    "\n",
    "print(im1.shape, im5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image(img, H, shape = (2000,2000,3)):\n",
    "    m,n,ch = shape #canvas size\n",
    "    indy, indx = np.indices((m, n), dtype=np.float32)\n",
    "    lin_homg_ind = np.array([indx.ravel(), indy.ravel(), np.ones_like(indx).ravel()])\n",
    "    #warping\n",
    "    map_ind = np.matmul(H, lin_homg_ind)\n",
    "    x, y = map_ind[:-1]/map_ind[-1]\n",
    "    x = x.reshape(m,n).astype(np.float32)\n",
    "    y = y.reshape(m,n).astype(np.float32)\n",
    "    warped_img = cv.remap(img, x, y, cv.INTER_LINEAR)\n",
    "    \n",
    "    return warped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8af9f46fa1c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbreakpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mstitch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     '''Stitch img1 onto img2\n\u001b[0;32m      4\u001b[0m         \u001b[0mimg2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mreference\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \t'''\n",
      "\u001b[1;32m<ipython-input-1-8af9f46fa1c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbreakpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mstitch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     '''Stitch img1 onto img2\n\u001b[0;32m      4\u001b[0m         \u001b[0mimg2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mreference\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \t'''\n",
      "\u001b[1;32mc:\\Users\\DELL\\.vscode\\extensions\\ms-python.python-2021.2.636928669\\pythonFiles\\lib\\python\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_line\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_suspend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_cmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_step_cmd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpydev_original_step_cmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_wait_suspend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m                     \u001b[1;32melif\u001b[0m \u001b[0mis_return\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# return event\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m                         \u001b[0mback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\.vscode\\extensions\\ms-python.python-2021.2.636928669\\pythonFiles\\lib\\python\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdo_wait_suspend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_wait_suspend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;31m# IFDEF CYTHON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\.vscode\\extensions\\ms-python.python-2021.2.636928669\\pythonFiles\\lib\\python\\debugpy\\_vendored\\pydevd\\pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   1853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_threads_suspended_single_notification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify_thread_suspended\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_reason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1855\u001b[1;33m                 \u001b[0mkeep_suspended\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_wait_suspend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframes_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m         \u001b[0mframes_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\.vscode\\extensions\\ms-python.python-2021.2.636928669\\pythonFiles\\lib\\python\\debugpy\\_vendored\\pydevd\\pydevd.py\u001b[0m in \u001b[0;36m_do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   1888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1889\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1890\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1891\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_current_thread_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def stitch(img1, img2, pad = (200, 200)):\n",
    "    '''Stitch img1 onto img2\n",
    "\timg2 - reference image\n",
    "\t'''\n",
    "    m,n,c = img2.shape\n",
    "    m += pad[0]\n",
    "    n += pad[1]\n",
    "    canvas = np.zeros((m, n, c))\n",
    "    canvas[0:img2.shape[0], 0:img2.shape[1]] = img2\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "             if np.all(img1[i][j]) != 0:\n",
    "                 canvas[i,j] = img1[i,j]\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.62544644, 0.057759174, 222.01217], [0.22240536, 1.1652147, -25.605611], [0.00049212545, -3.6542424e-05, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "# Image 1 to image 5\n",
    "with open('images/H1to5p') as f:\n",
    "    H = [[float(x) for x in line.split()] for line in f]\n",
    "print(H)\n",
    "H = np.array(H)\n",
    "\n",
    "im1_warped = warp_image(im1, np.linalg.inv(H), (1200,1200,3))\n",
    "im15 = stitch(im1_warped, im5, pad = 100)\n",
    "\n",
    "save_img(im1, 'im1')\n",
    "save_img(im5, 'im5')\n",
    "save_img(im1_warped,'image1warped')\n",
    "save_img(im15, 'im1to5')\n"
   ]
  },
  {
   "source": [
    "## 3. Stiching by selecting points from mouse click and using opencv functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 6.67833889e-01  4.74546565e-02  2.19691891e+02]\n [ 2.24630816e-01  1.15494975e+00 -1.97995354e+01]\n [ 5.54027726e-04 -6.70285922e-05  1.00000000e+00]]\n[[ 6.20252362e-01  3.39448550e-02  2.21593331e+02]\n [ 2.34315085e-01  1.09731364e+00 -2.45618192e+01]\n [ 4.95386157e-04 -1.29241854e-04  1.00000000e+00]]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 640 is out of bounds for axis 0 with size 640",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-4d80a5f71285>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mim1_m1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarpPerspective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mim15_m1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstitch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim1_m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'outputs/im15m1.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim15_m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-06aae73b0a20>\u001b[0m in \u001b[0;36mstitch\u001b[1;34m(img1, img2, pad)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m              \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                  \u001b[0mcanvas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 640 is out of bounds for axis 0 with size 640"
     ]
    }
   ],
   "source": [
    "N = 5     #Number of points to be selected\n",
    "global n\n",
    "n = 0\n",
    "p1 = np.empty((N,2))        #selected points on first image \n",
    "p2 = np.empty((N,2))        # selected points on second image \n",
    "\n",
    "#mouse callback function\n",
    "def draw_circle(event, x, y, flags, param):\n",
    "    global n \n",
    "    p = param[0]\n",
    "    if event == cv.EVENT_LBUTTONDOWN:\n",
    "        cv.circle(param[1], (x,y), 5, (255,0,0), -1)    #draws a circle on clicked point\n",
    "        p[n] = (x,y)\n",
    "        n += 1\n",
    "\n",
    "\n",
    "im1copy = im1.copy()\n",
    "im5copy = im5.copy()\n",
    "\n",
    "\n",
    "cv.namedWindow('Image 1', cv.WINDOW_AUTOSIZE)\n",
    "param = [p1, im1copy]\n",
    "cv.setMouseCallback('Image 1', draw_circle, param)\n",
    "\n",
    "while(1):\n",
    "    cv.imshow('Image 1', im1copy)\n",
    "    if n == N:\n",
    "        break\n",
    "    if cv.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv.namedWindow('Image 5', cv.WINDOW_AUTOSIZE)\n",
    "param = [p2, im5copy]\n",
    "cv.setMouseCallback('Image 5', draw_circle, param)\n",
    "n = 0\n",
    "while(1):\n",
    "    cv.imshow('Image 5', im5copy)\n",
    "    if n == N:\n",
    "        break\n",
    "    if cv.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 6.67833889e-01  4.74546565e-02  2.19691891e+02]\n",
      " [ 2.24630816e-01  1.15494975e+00 -1.97995354e+01]\n",
      " [ 5.54027726e-04 -6.70285922e-05  1.00000000e+00]]\n",
      "39.09625971079854\n"
     ]
    }
   ],
   "source": [
    "H1, status = cv.findHomography(p1,p2)\n",
    "\n",
    "H= np.array(H, dtype = np.float32)\n",
    "print(H1)\n",
    "\n",
    "im1_m1 = warp_image(im1, np.linalg.inv(H1), (1200,1200,3))\n",
    "im15_m1 = stitch(im1_m1, im5)\n",
    "\n",
    "cv.imwrite('outputs/im15m1.png', im15_m1)\n",
    "print(np.sum((H-H1)**2))"
   ]
  },
  {
   "source": [
    "## 4. Stitching images by selecting points from mouse click and computing homograpy with own code"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 6.67668288e-01  4.71601809e-02  2.19492779e+02]\n [ 2.24284933e-01  1.15325819e+00 -1.95866380e+01]\n [ 5.53305900e-04 -6.90841212e-05  1.00000000e+00]]\n42.57744920921803\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "# p1, p2 are use here as well\n",
    "A = []\n",
    "\n",
    "for i in range(N):\n",
    "    x, y = p1[i][0], p1[i][1]\n",
    "    u, v = p2[i][0], p2[i][1]\n",
    "    A.append([x, y, 1, 0, 0, 0, -u*x, -u*y, -u])\n",
    "    A.append([0, 0, 0, x, y, 1, -v*x, -v*y, -v])\n",
    "A = np.asarray(A)\n",
    "U, S, Vh = np.linalg.svd(A)\n",
    "L = Vh[-1,:] / Vh[-1,-1]\n",
    "h = L.reshape(3, 3)\n",
    "\n",
    "print(h)\n",
    "print(np.sum((H-h)**2))\n",
    "\n",
    "im1m3= cv.warpPerspective(im1, h, (1200,1200))\n",
    "im15m3 = stitch(im1m3, im5)\n",
    "cv.imwrite('outputs/im15m3.png', im15m3)\n"
   ]
  },
  {
   "source": [
    "## 5. Stitchong using superglue\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Cloning into 'SuperGluePretrainedNetwork'...\nUpdating files: 100% (89/89)\nUpdating files: 100% (89/89), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/magicleap/SuperGluePretrainedNetwork.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Namespace(cache=False, eval=False, fast_viz=False, force_cpu=False, input_dir='outputs/', input_pairs='SuperGluePretrainedNetwork/assets/match.txt', keypoint_threshold=0.005, match_threshold=0.2, max_keypoints=1024, max_length=-1, nms_radius=4, opencv_display=False, output_dir='outputs/matches/', resize=[-1], resize_float=False, show_keypoints=False, shuffle=False, sinkhorn_iterations=20, superglue='indoor', viz=True, viz_extension='png')\n",
      "Will not resize images\n",
      "Running inference on device \"cpu\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "Looking for data in directory \"outputs\"\n",
      "Will write matches to directory \"outputs\\matches\"\n",
      "Will write visualization images to directory \"outputs\\matches\"\n",
      "[Finished pair     0 of     1] load_image=0.089 matcher=6.756 viz_match=0.722 total=7.567 sec {0.1 FPS} \n",
      "d:\\Semester 4\\EN2550_Fundamentals of Image Processing and Machine Vision\\Assingments\\assignment2\\SuperGluePretrainedNetwork\\models\\superpoint.py:171: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n",
      "  torch.nonzero(s > self.config['keypoint_threshold'])\n"
     ]
    }
   ],
   "source": [
    "!python SuperGluePretrainedNetwork/match_pairs.py --viz --resize -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['keypoints0', 'keypoints1', 'matches', 'match_confidence']\n(1024, 2)\n-1\n310\n[ 79. 500.]\n"
     ]
    }
   ],
   "source": [
    "mat = np.load('outputs/matches/im1_im5_matches.npz')\n",
    "print(mat.files)\n",
    "print(mat['keypoints0'].shape)\n",
    "print(mat['matches'][2])\n",
    "print(np.sum(mat['matches'] > -1))\n",
    "print(mat['keypoints0'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(310, 2)\n"
     ]
    }
   ],
   "source": [
    "q1 = []\n",
    "q2 = []\n",
    "for i in range(len(mat['matches'])):\n",
    "    if mat['matches'][i] !=-1:\n",
    "        q1.append(mat['keypoints0'][i])\n",
    "        q2.append(mat['keypoints1'][mat['matches'][i]])\n",
    "q1 = np.asarray(q1)\n",
    "q2 = np.asarray(q2)\n",
    "print(q1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 6.2544644e-01  5.7759173e-02  2.2201218e+02]\n [ 2.2240536e-01  1.1652147e+00 -2.5605612e+01]\n [ 4.9212546e-04 -3.6542424e-05  1.0000000e+00]] \n [[ 6.17522839e-01  5.43293411e-02  2.22337085e+02]\n [ 2.16388403e-01  1.15471166e+00 -2.24786917e+01]\n [ 4.74669659e-04 -4.16988122e-05  1.00000000e+00]]\n9.883415981580645\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "h4, mask = cv.findHomography(q1, q2 , method = cv.RANSAC)\n",
    "print(H,'\\n', h4)\n",
    "print(np.sum((H-h4)**2))\n",
    "im1ran = cv.warpPerspective(im1, h4, (1200,1200))\n",
    "im15su = stitch(im1ran, im5)\n",
    "cv.imwrite('outputs/im15su.png', im15su)"
   ]
  },
  {
   "source": [
    "### Stitching multiple images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Namespace(cache=False, eval=False, fast_viz=False, force_cpu=False, input_dir='images', input_pairs='SuperGluePretrainedNetwork/assets/match.txt', keypoint_threshold=0.005, match_threshold=0.2, max_keypoints=1024, max_length=-1, nms_radius=4, opencv_display=False, output_dir='outputs/matches/', resize=[-1], resize_float=False, show_keypoints=False, shuffle=False, sinkhorn_iterations=20, superglue='indoor', viz=True, viz_extension='png')\n",
      "Will not resize images\n",
      "Running inference on device \"cpu\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "Looking for data in directory \"images\"\n",
      "Will write matches to directory \"outputs\\matches\"\n",
      "Will write visualization images to directory \"outputs\\matches\"\n",
      "[Finished pair     0 of     7] load_image=0.008 matcher=4.178 viz_match=0.805 total=4.991 sec {0.2 FPS} \n",
      "[Finished pair     1 of     7] load_image=0.008 matcher=4.195 viz_match=0.743 total=4.946 sec {0.2 FPS} \n",
      "[Finished pair     2 of     7] load_image=0.008 matcher=4.297 viz_match=0.682 total=4.987 sec {0.2 FPS} \n",
      "[Finished pair     3 of     7] load_image=0.008 matcher=4.211 viz_match=0.656 total=4.876 sec {0.2 FPS} \n",
      "[Finished pair     4 of     7] load_image=0.008 matcher=4.321 viz_match=0.655 total=4.984 sec {0.2 FPS} \n",
      "[Finished pair     5 of     7] load_image=0.008 matcher=4.292 viz_match=0.641 total=4.941 sec {0.2 FPS} \n",
      "d:\\Semester 4\\EN2550_Fundamentals of Image Processing and Machine Vision\\Assingments\\assignment2\\SuperGluePretrainedNetwork\\models\\superpoint.py:171: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n",
      "  torch.nonzero(s > self.config['keypoint_threshold'])\n",
      "Traceback (most recent call last):\n",
      "  File \"SuperGluePretrainedNetwork/match_pairs.py\", line 210, in <module>\n",
      "    name0, name1 = pair[:2]\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n"
     ]
    }
   ],
   "source": [
    "!python SuperGluePretrainedNetwork/match_pairs.py --viz --resize -1 --input_dir images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'m0': 454, 'm1': 257, 'm2': 227}\n"
     ]
    }
   ],
   "source": [
    "# loading outputs from superglue\n",
    "m1 = np.load('outputs/matches/img1_img2_matches.npz')\n",
    "m2 = np.load('outputs/matches/img2_img3_matches.npz')\n",
    "m3 = np.load('outputs/matches/img3_img4_matches.npz')\n",
    "matches = [m1, m2, m3]\n",
    "number_of_matches = {}\n",
    "for i in range(len(matches)):\n",
    "    number_of_matches['m' + str(i)] = np.sum(matches[i]['matches'] > -1)\n",
    "print(number_of_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images for multiple image stitching\n",
    "img1 = cv.imread('images\\img1.jpg', cv.IMREAD_COLOR)\n",
    "img2 = cv.imread('images\\img2.jpg', cv.IMREAD_COLOR)\n",
    "img3 = cv.imread('images\\img3.jpg', cv.IMREAD_COLOR)\n",
    "img4 = cv.imread('images\\img4.jpg', cv.IMREAD_COLOR)\n"
   ]
  },
  {
   "source": [
    "## Image order to be stiched\n",
    "(((1->2)->3)) ->4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_points(m):\n",
    "    q1 = []\n",
    "    q2 = []\n",
    "    for i in range(len(m['matches'])):\n",
    "        if mat['matches'][i] !=-1:\n",
    "            q1.append(m['keypoints0'][i])\n",
    "            q2.append(m['keypoints1'][m['matches'][i]])\n",
    "    q1 = np.asarray(q1)\n",
    "    q2 = np.asarray(q2)\n",
    "    return q1, q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stitching 1,2 \n",
    "points12 = find_matching_points(m1)\n",
    "\n",
    "h12, s= cv.findHomography(points12[0], points12[1], method= cv.RANSAC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_left(img1, img2, pad = (1000, 1000)):\n",
    "    '''Stitch img1 onto img2'''\n",
    "    m,n,c = img2.shape\n",
    "    m += pad[0]\n",
    "    n += pad[1]\n",
    "    canvas = np.zeros((m, n, c))\n",
    "    canvas[pad[0]:img2.shape[0]+pad[0], pad[1]:img2.shape[1]+pad[1]] = img2\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "             if np.all(img1[i][j]) != 0:\n",
    "                 canvas[i,j] = img1[i,j]\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H23 = np.matmul(h12, h23)\n",
    "mount2 = warp_image(img2, (h12), (2000,2000,3))\n",
    "mount2 = stitch(mount2, img1, pad = (50,350))\n",
    "\n",
    "save_img(mount2, 'mount21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Namespace(cache=False, eval=False, fast_viz=False, force_cpu=False, input_dir='outputs/', input_pairs='SuperGluePretrainedNetwork/assets/match.txt', keypoint_threshold=0.005, match_threshold=0.2, max_keypoints=1024, max_length=-1, nms_radius=4, opencv_display=False, output_dir='outputs/matches/', resize=[-1], resize_float=False, show_keypoints=False, shuffle=False, sinkhorn_iterations=20, superglue='indoor', viz=True, viz_extension='png')\n",
      "Will not resize images\n",
      "Running inference on device \"cpu\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "Looking for data in directory \"outputs\"\n",
      "Will write matches to directory \"outputs\\matches\"\n",
      "Will write visualization images to directory \"outputs\\matches\"\n",
      "[Finished pair     0 of     1] load_image=0.018 matcher=5.701 viz_match=0.788 total=6.507 sec {0.2 FPS} \n",
      "d:\\Semester 4\\EN2550_Fundamentals of Image Processing and Machine Vision\\Assingments\\assignment2\\SuperGluePretrainedNetwork\\models\\superpoint.py:171: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n",
      "  torch.nonzero(s > self.config['keypoint_threshold'])\n"
     ]
    }
   ],
   "source": [
    "!python SuperGluePretrainedNetwork/match_pairs.py --viz --resize -1 --input_dir outputs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(307, 2)\n[[-1.02971717e+00  1.55639253e+00  4.93011999e+02]\n [-9.83733552e-01  1.48691764e+00  4.71012704e+02]\n [-2.08822585e-03  3.15657553e-03  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "m = np.load('outputs/matches/mount21_img3_matches.npz')\n",
    "pts = find_matching_points(m)\n",
    "print(pts[1].shape)\n",
    "hf, s= cv.findHomography(pts[0], pts[1], method = cv.RANSAC)\n",
    "print(hf)\n",
    "mount = cv.warpPerspective(img3, hf, (1000,1000))\n",
    "save_img(mount, 'mount_temp')\n",
    "# mount = stitch(mount, mount2, pad = (1000,1000))\n",
    "\n",
    "# save_img(mount, 'mount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}